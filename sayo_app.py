import streamlit as st
import yt_dlp
import cv2
import numpy as np
import tempfile
import os
import warnings
from moviepy.editor import VideoFileClip, AudioFileClip, CompositeVideoClip, TextClip, ColorClip
import soundfile as sf
import librosa
from scipy import signal
from scipy.ndimage import gaussian_filter1d
from sklearn.preprocessing import StandardScaler
from datetime import datetime

# Supprimer les warnings
warnings.filterwarnings("ignore")

# Configuration Streamlit
st.set_page_config(
    page_title="SAYO - Smart Audio Dimming MVP",
    page_icon="üé•",
    layout="wide"
)

# CSS personnalis√© pour le branding SAYO
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #ff5c1c 0%, #ff8c42 100%);
        padding: 2rem;
        border-radius: 15px;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 8px 25px rgba(255, 92, 28, 0.3);
    }
    .main-header h1 {
        color: white;
        font-size: 3.5rem;
        margin: 0;
        font-weight: bold;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
    }
    .main-header p {
        color: white;
        font-size: 1.4rem;
        margin: 0.5rem 0 0 0;
        opacity: 0.95;
    }
    .feature-box {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 1.5rem;
        border-radius: 12px;
        border-left: 5px solid #ff5c1c;
        margin: 1rem 0;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    .step-indicator {
        background: linear-gradient(135deg, #ff5c1c 0%, #ff7b42 100%);
        color: white;
        border-radius: 50%;
        width: 35px;
        height: 35px;
        display: inline-flex;
        align-items: center;
        justify-content: center;
        font-weight: bold;
        margin-right: 15px;
        box-shadow: 0 3px 10px rgba(255, 92, 28, 0.4);
    }
    .success-box {
        background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%);
        border: 1px solid #b4d8c1;
        color: #155724;
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
        box-shadow: 0 3px 12px rgba(0,0,0,0.1);
    }
    .magic-moment {
        background: linear-gradient(135deg, #fff3e0 0%, #ffe0b2 100%);
        border: 2px solid #ff9800;
        padding: 1.5rem;
        border-radius: 12px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Header principal
st.markdown("""
<div class="main-header">
    <h1>üé• SAYO</h1>
    <p>Smart Audio Dimming MVP - Ta r√©action. Ton style. En un instant.</p>
</div>
""", unsafe_allow_html=True)

# Initialisation des variables de session
if 'video_downloaded' not in st.session_state:
    st.session_state.video_downloaded = False
if 'video_path' not in st.session_state:
    st.session_state.video_path = None
if 'audio_recorded' not in st.session_state:
    st.session_state.audio_recorded = False
if 'video_info' not in st.session_state:
    st.session_state.video_info = None

# Fonctions principales
@st.cache_data
def download_youtube_video(url, max_duration=300):
    """T√©l√©charge une vid√©o YouTube optimis√©e"""
    try:
        ydl_opts = {
            'format': 'best[height<=720][ext=mp4]/best[ext=mp4]',
            'outtmpl': '/tmp/sayo_video.%(ext)s',
            'noplaylist': True,
            'no_warnings': True,
            'quiet': True,
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=False)
            duration = info.get('duration', 0)
            title = info.get('title', 'Vid√©o sans titre')
            
            if duration > max_duration:
                return None, f"Vid√©o trop longue ({duration//60}min {duration%60}s). Maximum 5 minutes."
            
            ydl.download([url])
            video_path = '/tmp/sayo_video.mp4'
            
            if os.path.exists(video_path):
                return video_path, {"title": title, "duration": duration, "url": url}
            else:
                return None, "Fichier vid√©o non trouv√©"
                
    except Exception as e:
        return None, f"Erreur: {str(e)}"

def simulate_transcription(audio_file):
    """Simule la transcription en attendant Whisper"""
    sample_transcriptions = [
        "Oh wow, c'est incroyable ! Je n'avais jamais vu √ßa avant.",
        "C'est exactement ce que je pensais qu'il allait faire !",
        "Attendez, qu'est-ce qui se passe l√† ? C'est g√©nial !",
        "Haha, j'adore cette partie ! Vraiment bien fait.",
        "Non mais s√©rieusement, c'est du niveau professionnel √ßa !"
    ]
    import random
    return random.choice(sample_transcriptions)

def apply_smart_dimming(original_audio, reaction_audio):
    """Applique le smart audio dimming basique"""
    try:
        # Analyser l'√©nergie de la r√©action
        reaction_energy = librosa.feature.rms(y=reaction_audio)[0]
        
        # Seuil de d√©tection de parole
        threshold = np.mean(reaction_energy) * 1.5
        
        # Cr√©er un masque pour les moments de parole
        speaking_frames = reaction_energy > threshold
        
        # Appliquer le dimming avec interpolation
        dimmed_audio = original_audio.copy()
        
        # Convertir frame-based mask vers time-based
        hop_length = 512
        frame_to_time = hop_length / 22050
        
        for i, is_speaking in enumerate(speaking_frames):
            start_time = i * frame_to_time
            end_time = (i + 1) * frame_to_time
            
            start_sample = int(start_time * 22050)
            end_sample = int(end_time * 22050)
            
            if end_sample > len(dimmed_audio):
                end_sample = len(dimmed_audio)
                
            if is_speaking:
                # Dimming agressif quand l'utilisateur parle
                dimmed_audio[start_sample:end_sample] *= 0.25
        
        return dimmed_audio
        
    except Exception as e:
        st.error(f"Erreur dimming: {str(e)}")
        return original_audio * 0.5  # Fallback simple

def create_reaction_video(video_path, audio_bytes, transcription):
    """Cr√©e une vid√©o de r√©action avec Smart Audio Dimming"""
    try:
        # Charger la vid√©o originale
        original_video = VideoFileClip(video_path)
        
        # Sauvegarder l'audio de r√©action
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_audio:
            tmp_audio.write(audio_bytes)
            reaction_audio_path = tmp_audio.name
        
        # Charger les audios
        original_audio_data, sr1 = librosa.load(video_path, sr=22050)
        reaction_audio_data, sr2 = librosa.load(reaction_audio_path, sr=22050)
        
        # Ajuster les longueurs
        min_length = min(len(original_audio_data), len(reaction_audio_data))
        original_audio_data = original_audio_data[:min_length]
        reaction_audio_data = reaction_audio_data[:min_length]
        
        # Appliquer le Smart Audio Dimming
        dimmed_audio = apply_smart_dimming(original_audio_data, reaction_audio_data)
        
        # Combiner les audios
        final_audio_data = dimmed_audio + reaction_audio_data * 0.8
        
        # Sauvegarder l'audio final
        final_audio_path = "/tmp/final_audio.wav"
        sf.write(final_audio_path, final_audio_data, 22050)
        final_audio_clip = AudioFileClip(final_audio_path)
        
        # Cr√©er la vid√©o format vertical
        target_width = 1080
        target_height = 1920
        
        # Redimensionner vid√©o originale
        video_height = int(target_height * 0.65)
        video_width = int(video_height * original_video.w / original_video.h)
        
        if video_width > target_width:
            video_width = target_width
            video_height = int(video_width * original_video.h / original_video.w)
        
        resized_video = original_video.resize((video_width, video_height)).set_position(('center', 100))
        
        # Fond noir
        background = ColorClip(size=(target_width, target_height), color=(0,0,0), duration=original_video.duration)
        
        # Zone de r√©action SAYO
        reaction_zone = ColorClip(
            size=(target_width-80, 350), 
            color=(255, 92, 28),
            duration=original_video.duration
        ).set_position((40, target_height - 390)).set_opacity(0.9)
        
        # Texte de r√©action
        reaction_text = TextClip(
            "üé§ Smart Audio Dimming activ√©\n‚ú® Votre r√©action analys√©e",
            fontsize=28,
            color='white',
            font='Arial-Bold',
            align='center'
        ).set_duration(original_video.duration).set_position(('center', target_height - 250))
        
        # Logo SAYO
        sayo_logo = TextClip(
            "SAYO",
            fontsize=40,
            color='white',
            font='Arial-Bold'
        ).set_duration(original_video.duration).set_position((40, 40))
        
        # Sous-titre avec transcription
        subtitle = TextClip(
            transcription,
            fontsize=24,
            color='white',
            bg_color='rgba(0,0,0,0.8)',
            size=(target_width-120, None),
            method='caption'
        ).set_duration(min(5, original_video.duration)).set_position(('center', target_height - 450))
        
        # Composer la vid√©o finale
        video_clips = [background, resized_video, reaction_zone, reaction_text, sayo_logo, subtitle]
        final_video = CompositeVideoClip(video_clips, size=(target_width, target_height))
        
        # Ajuster l'audio final
        if final_audio_clip.duration > final_video.duration:
            final_audio_clip = final_audio_clip.subclip(0, final_video.duration)
        elif final_audio_clip.duration < final_video.duration:
            final_audio_clip = final_audio_clip.loop(duration=final_video.duration)
        
        final_video = final_video.set_audio(final_audio_clip)
        
        # Exporter
        output_path = "/tmp/sayo_reaction_final.mp4"
        final_video.write_videofile(
            output_path,
            fps=24,
            codec='libx264',
            audio_codec='aac',
            verbose=False,
            logger=None
        )
        
        # Nettoyage
        os.unlink(reaction_audio_path)
        os.unlink(final_audio_path)
        original_video.close()
        final_audio_clip.close()
        final_video.close()
        
        return output_path, "‚úÖ Vid√©o SAYO cr√©√©e avec Smart Audio Dimming!"
        
    except Exception as e:
        return None, f"‚ùå Erreur: {str(e)}"

# Interface utilisateur
st.markdown("### üé¨ Cr√©ez votre vid√©o de r√©action avec Smart Audio Dimming")

# √âtape 1: Import YouTube
st.markdown('<div class="step-indicator">1</div> **Importer une vid√©o YouTube**', unsafe_allow_html=True)

col1, col2 = st.columns([3, 1])

with col1:
    youtube_url = st.text_input(
        "URL de la vid√©o YouTube (max 5 min)",
        placeholder="https://www.youtube.com/watch?v=dQw4w9WgXcQ",
        help="Collez l'URL d'une vid√©o YouTube de moins de 5 minutes"
    )

with col2:
    download_btn = st.button("üì• T√©l√©charger", type="primary")

if download_btn and youtube_url:
    with st.spinner("T√©l√©chargement en cours..."):
        video_path, result = download_youtube_video(youtube_url)
        
        if video_path:
            st.session_state.video_downloaded = True
            st.session_state.video_path = video_path
            st.session_state.video_info = result
            st.success(f"‚úÖ Vid√©o t√©l√©charg√©e: {result['title']}")
        else:
            st.error(f"‚ùå {result}")

# √âtape 2: Pr√©visualisation
if st.session_state.video_downloaded:
    st.markdown('<div class="step-indicator">2</div> **Pr√©visualisation de la vid√©o**', unsafe_allow_html=True)
    
    col3, col4 = st.columns([2, 1])
    
    with col3:
        if os.path.exists(st.session_state.video_path):
            st.video(st.session_state.video_path)
    
    with col4:
        if st.session_state.video_info:
            st.markdown(f"""
            <div class="feature-box">
                <h4>üìä Infos vid√©o</h4>
                <p><strong>Titre:</strong> {st.session_state.video_info['title'][:50]}...</p>
                <p><strong>Dur√©e:</strong> {st.session_state.video_info['duration']//60}min {st.session_state.video_info['duration']%60}s</p>
            </div>
            """, unsafe_allow_html=True)

# √âtape 3: Enregistrement audio
st.markdown('<div class="step-indicator">3</div> **Enregistrer votre r√©action**', unsafe_allow_html=True)

col5, col6 = st.columns([2, 1])

with col5:
    st.info("üì± Enregistrez votre r√©action avec votre t√©l√©phone puis uploadez le fichier audio")
    
    uploaded_audio = st.file_uploader(
        "Uploadez votre r√©action audio",
        type=['wav', 'mp3', 'm4a', 'ogg'],
        help="Formats support√©s: WAV, MP3, M4A, OGG"
    )
    
    if uploaded_audio:
        st.session_state.audio_recorded = True
        st.success("‚úÖ Audio de r√©action upload√©!")
        st.audio(uploaded_audio)

with col6:
    st.markdown("""
    <div class="feature-box">
        <h4>üé§ Smart Dimming</h4>
        <p>‚Ä¢ Parlez naturellement</p>
        <p>‚Ä¢ L'IA d√©tecte votre voix</p>
        <p>‚Ä¢ Audio original diminu√© automatiquement</p>
        <p>‚Ä¢ Transitions fluides</p>
    </div>
    """, unsafe_allow_html=True)

# √âtape 4: G√©n√©ration
if st.session_state.video_downloaded and st.session_state.audio_recorded:
    st.markdown('<div class="step-indicator">4</div> **G√©n√©ration avec Smart Audio Dimming**', unsafe_allow_html=True)
    
    if st.button("üöÄ G√©n√©rer la vid√©o SAYO", type="primary"):
        with st.spinner("Transcription et traitement..."):
            # Simulation transcription
            transcription = simulate_transcription(uploaded_audio)
            st.success("‚úÖ Transcription simul√©e termin√©e!")
            st.write(f"**Transcription:** *{transcription}*")
            
            # G√©n√©ration vid√©o avec Smart Dimming
            video_result, message = create_reaction_video(
                st.session_state.video_path,
                uploaded_audio.getvalue(),
                transcription
            )
            
            if video_result and os.path.exists(video_result):
                st.success(message)
                st.video(video_result)
                
                # T√©l√©chargement
                with open(video_result, "rb") as f:
                    video_bytes = f.read()
                
                st.download_button(
                    label="üì± T√©l√©charger votre vid√©o SAYO",
                    data=video_bytes,
                    file_name=f"sayo_reaction_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4",
                    mime="video/mp4"
                )
                
                st.markdown("""
                <div class="success-box">
                    <h4>üéâ Smart Audio Dimming appliqu√©!</h4>
                    <p>‚úÖ D√©tection automatique de votre voix</p>
                    <p>‚úÖ Audio original diminu√© intelligemment</p>
                    <p>‚úÖ Format vertical optimis√©</p>
                    <p>‚úÖ Qualit√© professionnelle</p>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.error(message)

# Info technique
st.markdown("""
<div class="magic-moment">
    <h4>‚ú® Smart Audio Dimming - Version MVP</h4>
    <p><strong>üß† D√©tection :</strong> Analyse de l'√©nergie vocale en temps r√©el</p>
    <p><strong>üîâ Dimming :</strong> R√©duction automatique √† 25% quand vous parlez</p>
    <p><strong>‚ö° Performance :</strong> Traitement optimis√© pour Streamlit Cloud</p>
    <p><strong>üéØ Prochaine √©tape :</strong> Int√©gration Whisper pour transcription IA</p>
</div>
""", unsafe_allow_html=True)

# Footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; padding: 2rem;">
    <h3 style="color: #ff5c1c;">üé• SAYO MVP - Smart Audio Dimming</h3>
    <p><strong>Version:</strong> 1.0 Simplified | <strong>Status:</strong> D√©ploy√© sur Streamlit Cloud</p>
    <p>üîâ Smart Dimming ‚Ä¢ üì± Format Vertical ‚Ä¢ ‚ö° Traitement Temps R√©el</p>
</div>
""", unsafe_allow_html=True)
